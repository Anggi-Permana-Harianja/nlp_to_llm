{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6ab736-df9c-463a-bb6c-d776617ed715",
   "metadata": {},
   "source": [
    "# Implementing Self-Attention from Scratch in PyTorch with Example\n",
    "\n",
    "In this notebook, we'll build a self-attention mechanism from scratch and demonstrate it with a short example.\n",
    "\n",
    "## Import Libraries\n",
    "\n",
    "First, let's import the necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c396fa6c-9ad1-4ef4-9dec-d923f0f5785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b6ee7-9f51-4bbb-8461-2cecbafe7067",
   "metadata": {},
   "source": [
    "## Step-by-Step Implementation\n",
    "\n",
    "### Step 1: Initialize Parameters\n",
    "\n",
    "We'll start by defining the necessary parameters and initializing the weight matrices for queries, keys, and values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78496ffe-ddd4-4b99-a55a-b396442641b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 256\n",
    "heads = 8\n",
    "head_dim = embed_size // heads\n",
    "\n",
    "# Initialize weight matrices for queries, keys, and values\n",
    "W_Q = torch.rand((embed_size, embed_size))\n",
    "W_K = torch.rand((embed_size, embed_size))\n",
    "W_V = torch.rand((embed_size, embed_size))\n",
    "\n",
    "# Initialize the final output weight matrix\n",
    "W_O = torch.rand((embed_size, embed_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b30dac-5116-4ebf-bd5d-c93bda651018",
   "metadata": {},
   "source": [
    "### Step 2: Define Input Tensors\n",
    "\n",
    "Let's create some dummy input tensors for values, keys, and queries. We'll use a simple example with a batch size of 1 and a sequence length of 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce2ae6db-bfe3-48f4-8bd6-27868b8a9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "seq_length = 3\n",
    "\n",
    "# Example sentences represented as random tensors\n",
    "values = torch.rand((batch_size, seq_length, embed_size))\n",
    "keys = torch.rand((batch_size, seq_length, embed_size))\n",
    "queries = torch.rand((batch_size, seq_length, embed_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a953016-12b4-402c-9356-c4dafb0ba6cf",
   "metadata": {},
   "source": [
    "### Step 3: Linear Transformations\n",
    "\n",
    "Apply the linear transformations to the input tensors using the weight matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27e2df9-15ee-4b9a-8822-8125a70c30c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.einsum('bse, ee->bse', queries, W_Q)\n",
    "K = torch.einsum('bse, ee->bse', keys, W_K)\n",
    "V = torch.einsum('bse, ee->bse', values, W_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471fc429-44c7-451a-9cb7-bb691a4cedf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
